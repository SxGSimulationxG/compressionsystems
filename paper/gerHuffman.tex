\subsection{Huffman Codierung}
Die Huffman-Kodierung ist ein Verfahren zur Erstellung eines optimalen Präfixcodes für ein gegebenes Sequenzcode mit bekannten Wahrscheinlichkeiten. Das Grundprinzip besteht darin, dass häufig auftretende Symbole kürzere und seltene längere Codewörter erhalten. Zu Beginn wird die Sequenzcode $\mathcal{S}$ nach absteigender Wahrscheinlichkeit sortiert. Jedes Symbol $s_i$ wird durch einen Knoten $q_i$ mit Gewicht $\tau_i = p_i$ in der Liste $\mathcal{Q}$ dargestellt. 

\begin{equation}
	p_i\geq p_{i+1}\geq \dots \geq p_m
\end{equation}
\begin{equation}
	q_i \leftarrow s_i, (\tau_i= p_i)
\end{equation}

Wir nehmen dann maximal $r$, mindestens jedoch 2 Zeichen mit der geringsten Wahrscheinlichkeit, verbinden sie mit einem neuen Knoten und fügen diesen neuen Knoten wieder in die richtige Position entsprechend seinem Gewicht in das Array $\mathcal{Q}$ ein. Durch das wiederholte Zusammenfassen der unwahrscheinlichsten Knoten entstehen in der Baumstruktur kurze Wege für häufige Symbole und lange Wege für seltene. Dadurch wird die Gesamtlänge aller Codewörter minimiert. 

\begin{equation}
	q_{new}\leftarrow {q_{new}}_j, \tau_{new}=\sum \tau_i
\end{equation}

Dieser Vorgang wird so lange wiederholt, bis der gesamte Wahrscheinlichkeitsraum durch einen einzigen Wurzelknoten mit $\tau_{new}=1$ dargestellt wird. Am Ende kann man den Kompressionsbaum visualisieren, indem man die Kinder jedes Knotens nachverfolgen, bis man die Quellzeichen erreicht\footnote{\cite{huffmanOriginal} S.1011: Generalization of the Method; \cite{rueda2002advances} S.50: Algorithm 1 Static Huffman Encoding}.

\subsubsection{Beispiel: Statisches Huffman Codierung}

Eingabe:
\begin{itemize}
	\item $\mathcal{S}=\{a,b,c,d,e,f,g,h\}$
	\item $\mathcal{P}=\{0.22,0.20,0.18,0.15,0.10,0.08,0.05,0.02\}$
	\item $\mathcal{A}=\{0,1,2,3\}$
\end{itemize}

\begin{table}[ht]
	\centering
	\begin{tabular}{cccc}
		$s_i$ & $p_i$ & $L_i$ & Code \\
		a & 0.22 & 1 & 1 \\
		b & 0.20 & 1 & 2 \\
		c & 0.18 & 1 & 3 \\
		d & 0.15 & 2 & 00 \\
		e & 0.10 & 2 & 01 \\
		f & 0.08 & 2 & 02 \\
		g & 0.05 & 3 & 030 \\
		h & 0.02 & 3 & 031 \\
	\end{tabular}
	\caption{Beispiel von \cite{huffmanOriginal} S.1101: Table III}
	\label{tab:placeholder}
\end{table}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1.1\linewidth]{huffmanTree}
	\caption{Huffman Baum von Tabelle 3; Mit Manim Community v0.19.0 erstellt}
	\label{fig:huffmantree}
\end{figure}

In Abbildung 2 stellen die grünen Knoten die einzelnen Zeichen mit ihren entsprechenden Wahrscheinlichkeiten $p$ dar, während die violetten Knoten die Verbindungsknoten $q$ mit ihrem entsprechenden Gewicht $\tau$ darstellen. Bei der Kodierung und Dekodierung verwenden wir diesen Baum als Übersetzungshilfe, wobei der am weitesten links stehende Knoten 0 ist, dann 1 usw.

\newpage

\subsubsection{Adaptive Huffman Codierung}
Die adaptive oder dynamische Huffman-Kodierung erweitert das klassische statische Verfahren um die Fähigkeit, sich während der Kodierung automatisch an Veränderungen der Symbolhäufigkeiten anzupassen. Im Gegensatz zur statischen Variante, bei der die Wahrscheinlichkeiten der Symbole im Voraus bekannt sein müssen, wird der Huffman-Baum hier fortlaufend angepasst, während die Eingabedaten gelesen werden. Dadurch kann die Kompression in einem einzigen Durchlauf erfolgen, ohne dass ein vorheriger Statistikaufbau erforderlich ist. Die Grundidee besteht darin, dass der Baum nach jedem neu eingelesenen Zeichen so umstrukturiert wird, dass er weiterhin die optimalen Eigenschaften der Huffman-Kodierung erfüllt. Diese Eigenschaft wird durch die sogenannte Geschwister-Eigenschaft (engl. sibling property) definiert. Sie besagt, dass für eine gegebene Kodierung der Baum genau dann optimal ist, wenn alle Knoten in absteigender Reihenfolge ihrer Gewichtungen angeordnet werden können und jedes Knotenpaar von Geschwistern aufeinanderfolgende Positionen in dieser Ordnung einnimmt\footnote{\cite{gallager2003variations} S.6: 2. The Sibling Property Definition}. In einem binären System besteht jeder Knoten (oder jedes Geschwisterpaar) aus fünf Komponenten: zwei Zählern für die untergeordneten Knoten, zwei Zeigern auf diese untergeordneten Knoten sowie einem Zeiger auf den übergeordneten Knoten. Jeder dieser Zeiger enthält zusätzlich die Information, ob es sich um den linken (0) oder rechten (1) Kindknoten handelt. Das Verfahren arbeitet fortlaufend: Als Eingabe dient der aktuelle Huffman-Baum sowie das nächste zu kodierende Zeichen. Nach jedem Schritt wird das Gewicht des entsprechenden Knotens – also die Häufigkeit des Symbols – um eins erhöht. Dadurch kann sich die Reihenfolge der Knoten ändern: Sobald ein Knoten ein höheres Gewicht erreicht als das nächstgrößere Geschwisterpaar, werden die beiden Knoten vertauscht. Auf diese Weise bleibt der Baum stets in einer Form, die der optimalen Huffman-Struktur entspricht. Wird ein bisher unbekanntes Symbol eingelesen, so wird ein neuer Knoten für dieses Symbol eingefügt und in die bestehende Baumstruktur integriert. Die Kodierung erfolgt dann unmittelbar mit dem aktualisierten Baum, sodass die Methode immer konsistent bleibt. Das Dekodieren kann parallel erfolgen, da der Empfänger dieselbe Abfolge von Baumaktualisierungen nachvollzieht. Diese adaptive Methode wurde von Robert G. Gallager vorgeschlagen, der die theoretischen Grundlagen der Geschwister-Eigenschaft entwickelte und zeigte, dass sie eine eindeutige und optimale Baumstruktur garantiert, solange die Aktualisierungsregeln eingehalten werden\footnote{\cite{gallager2003variations} S.17–21: Adaptive Huffman Codes}. Donald E. Knuth verbesserte später Gallagers System, indem er effiziente Verfahren zur Verwaltung der Knoten und zum Umgang mit der Verringerung von Symbolzählern einführte, falls Zeichen aus dem Datenstrom entfernt werden\footnote{\cite{knuthDynamicHuffman} S.163–165: Introduction}. Das adaptive Huffman-System stellt somit eine effiziente Lösung für Echtzeit-Kompression dar, insbesondere in Szenarien, in denen die Symbolwahrscheinlichkeiten nicht im Voraus bekannt oder nicht konstant sind.