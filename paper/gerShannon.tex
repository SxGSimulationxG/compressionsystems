\subsection{Shannon Codierung}
Auch wenn die von Claude E. Shannon vorgeschlagene Shannon-Methode aufgrund ihrer Ineffizienz hinsichtlich der resultierenden Kompressionsgröße nicht häufig verwendet wird, hat sie dennoch eine gewisse Relevanz in diesem Bereich. Dieses System liefert eine eindeutige Zahlenfolge, indem es eine kumulative Wahrscheinlichkeitsfunktion $P_i$ verwendet und dann die ersten $l_i$ Ziffern der $r$-ten Dezimaldarstellung der kumulativen Wahrscheinlichkeitsfunktion nimmt, um das entsprechende Codewort zu erstellen\footnote{\cite{rueda2002advances} p.52-53: 2.4.2 Shannon's Method; \cite{shannonMathematicalCommunication} p.401-403: 9. The Fundamental Theorem for a Noiseless Channel}.

\begin{equation}
	P_i = \left\{
	\begin{array}{lll}
		0 & \textbf{for} & i = 1 \\
		P_{i-1} + p_{i-1} & \textbf{for} & 2 \leq i \leq m
	\end{array}
	\right.
\end{equation}


\begin{equation}
	l_i=\lceil log_r(p_i^{-1})\rceil
\end{equation}

Shannon stellt außerdem fest, dass mit zunehmender Länge $N$ unserer Eingabesequenz die durchschnittliche Länge des Codeworts $H'$ sich der Entropie $H$ annähert.

\begin{equation}
	H'=\frac{1}{N} \sum(m_s p_s)
\end{equation}

Hier ist $p_s$ der Wert für die kumulative Wahrscheinlichkeitsfunktion $P_i$. $m_s$ ist eine ganze Zahl, wobei:
\begin{equation}
	\log_2(\frac{1}{p_s}) \leq m_s < \log_2(\frac{1}{p_s}) + 1
\end{equation}

\begin{equation}
	H \leq H' < H + \frac{1}{N}
\end{equation}

Wenn diese Annahme richtig ist, bestätigt dies die Intuition, dass ein Komprimierungssystem bei längeren Eingaben umso effektiver ist, auch wenn das Komprimierungssystem nicht optimal ist. Der Wert für die durchschnittliche Codewortlänge kann jedoch niemals unter den Wert für die Entropie $H$ fallen, ohne dass Informationen verloren gehen.

\subsubsection{Beispiel: Statisches Shannon Kodierung}

Eingabe:
\begin{itemize}
	\item $\mathcal{S}=\{a,b,c,d,e,f,g,h\}$
	\item $\mathcal{P}=\{0.22,0.20,0.18,0.15,0.10,0.08,0.05,0.02\}$
	\item $\mathcal{A}=\{0,1\} \to r=2$
\end{itemize}

\begin{table}[ht]
	\centering
	\begin{tabular}{c|c|c|c|c|c}
		$s_i$ & $p_i$ & $P_i$ & $l_i$ & $r$-Darstellung von $P_i$ & Code \\
		a & 0.22 & 0 & 3 & $0.000\dots$ & 000 \\
		b & 0.20 & 0.22 & 3 & $0.001\dots$ & 001 \\
		c & 0.18 & 0.42 & 3 & $0.011\dots$ & 011 \\
		d & 0.15 & 0.60 & 3 & $0.100\dots$ & 100 \\
		e & 0.10 & 0.75 & 4 & $0.11$ & 1100 \\
		f & 0.08 & 0.85 & 4 & $0.1101\dots$ & 1101 \\
		g & 0.05 & 0.93 & 5 & $0.11101\dots$ & 11101 \\
		h & 0.02 & 0.98 & 6 & $0.111110\dots$ & 111110 \\
	\end{tabular}
	\caption{Angepasst aus Beispiel von \cite{huffmanOriginal} p.1101: Table III}
	\label{tab:placeholder}
\end{table}

\todo{encoding scheme}

\subsubsection{Adaptive Shannon Kodierung}

Travis Gagie schlägt eine Methode zur Erstellung eines adaptiven Shannon-Kodierungssystems vor. Bei dieser Methode werden die Aufgaben in Vordergrund- und Hintergrundaufgaben unterteilt. Die Vordergrundaufgabe berücksichtigt das Gewicht der vorherigen Zeichenanzahl und aktualisiert die Gewichte entsprechend dem neu eingegebenen Zeichen. Befindet sich das Zeichen noch nicht im Kodierungsschema, wird der Knoten zur Zeichenanzahl hinzugefügt. Im Hintergrund wird für jedes im Vordergrund verarbeitete Zeichen ein Zeichen im Hintergrund verarbeitet. Die Gewichtung eines bestimmten Zeichens $a$ wird dann aktualisiert, wenn das Zeichen zuvor aufgetreten ist, oder es wird mit der Gewichtung, die der Wahrscheinlichkeit des Zeichens entspricht, zum Komprimierungsbaum hinzugefügt\footnote{\cite{gagie2004dynamic} p.3-4: III Dynamic Shannon Coding}. Dieses System ähnelt dem adaptiven Fano-Kodierungssystem mit der Brute-Force-Methode, das später behandelt wird. 